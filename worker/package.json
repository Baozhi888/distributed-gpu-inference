{
  "name": "gpu-worker",
  "version": "1.0.1",
  "description": "Distributed GPU Inference Worker - Share idle GPU computing power for LLM and image generation",
  "keywords": [
    "gpu",
    "inference",
    "distributed",
    "machine-learning",
    "llm",
    "stable-diffusion",
    "cuda",
    "pytorch",
    "transformers",
    "vllm",
    "sglang"
  ],
  "author": "Baozhi888 <kj331704@gmail.com>",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/Baozhi888/distributed-gpu-inference.git",
    "directory": "worker"
  },
  "homepage": "https://github.com/Baozhi888/distributed-gpu-inference#readme",
  "bugs": {
    "url": "https://github.com/Baozhi888/distributed-gpu-inference/issues"
  },
  "bin": {
    "gpu-worker": "bin/gpu-worker.js"
  },
  "scripts": {
    "postinstall": "node scripts/postinstall.js",
    "start": "node bin/gpu-worker.js start",
    "configure": "node bin/gpu-worker.js configure",
    "status": "node bin/gpu-worker.js status"
  },
  "engines": {
    "node": ">=16.0.0"
  },
  "os": [
    "win32",
    "linux",
    "darwin"
  ],
  "files": [
    "bin/",
    "scripts/",
    "engines/",
    "distributed/",
    "*.py",
    "*.yaml",
    "*.txt",
    "!.env*",
    "README.md"
  ],
  "dependencies": {
    "chalk": "^4.1.2",
    "commander": "^11.1.0",
    "inquirer": "^8.2.6",
    "ora": "^5.4.1",
    "which": "^3.0.1"
  }
}
